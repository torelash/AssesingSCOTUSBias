{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from time import time, sleep\n",
    "import json\n",
    "import requests\n",
    "import random\n",
    "random.seed(11)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# model-specific\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (30407, 32)\n",
      "Total html parsing time: 1.1 minutes\n",
      "After parsing html, there are 0 empty opinions remaining\n",
      "2 (30407, 14)\n",
      "3 (28904, 14)\n",
      "\n",
      "\n",
      "***SANITY CHECK {}***: \n",
      " CASE NAME: Williams Co. v. Shoe MacH. Corp. \n",
      " CASE DATE: 1942-05-25 00:00:00 \n",
      " \n",
      " CASE TEXT:\n",
      " 316 U.S. 364 (1942)\n",
      "WILLIAMS MANUFACTURING CO.\n",
      "v.\n",
      "UNITED SHOE MACHINERY CORP.\n",
      "No. 332.\n",
      "Supreme Court of United States.\n",
      "Argued February 13, 1942.\n",
      "Decided May 25, 1942.\n",
      "CERTIORARI TO THE CIRCUIT COURT OF APPEALS FOR THE SIXTH DISTRICT.\n",
      "Mr. H.A. Toulmin, Jr. for petitioner.\n",
      "Mr. Harrison F. Lyman, with whom Messrs. Charles E. Hammett, Jr. and Thomas J. Ryan were on the brief, for respondent.\n",
      "MR. JUSTICE ROBERTS delivered the opinion of the Court.\n",
      "The suit was for the infringement of Claims 6, 23, 42\n",
      "\n",
      "\n",
      "***SANITY CHECK {}***: \n",
      " CASE NAME: Jacobs v. Baker \n",
      " CASE DATE: 1869-03-22 00:00:00 \n",
      " \n",
      " CASE TEXT:\n",
      " 74 U.S. 295\n",
      "    19 L. Ed. 200\n",
      "    7 Wall. 295\n",
      "    JACOBSv.BAKER.\n",
      "    December Term, 1868\n",
      "    \n",
      "      JACOBS filed a bill in the Circuit Court for Southern Ohio against Baker, seeking relief for the infringement of four separate patents, which had been granted to him, Jacobs, for improvements in the construction of prisons. The bill set forth the different patents.\n",
      "      The first, dated January 7th, 1859, was for an improvement in the construction of prisons, which the complainant set forth in hi\n",
      "\n",
      "\n",
      "***SANITY CHECK {}***: \n",
      " CASE NAME: Missouri Pacific R. Co. v. David \n",
      " CASE DATE: 1932-02-15 00:00:00 \n",
      " \n",
      " CASE TEXT:\n",
      " 284 U.S. 460 (1932)\n",
      "MISSOURI PACIFIC RAILROAD CO.\n",
      "v.\n",
      "DAVID, ADMINISTRATRIX.\n",
      "No. 365.\n",
      "Supreme Court of United States.\n",
      "Argued January 20, 1932.\n",
      "Decided February 15, 1932.\n",
      "CERTIORARI TO THE SUPREME COURT OF MISSOURI.\n",
      "*461 Mr. Leslie A. Welch, with whom Messrs. Edward J. White and Thomas Hackney were on the brief, for petitioner.\n",
      "Mr. C.A. Randolph, with whom Mr. Horace Guffin was on the brief, for respondent.\n",
      "MR. JUSTICE McREYNOLDS delivered the opinion of the Court.\n",
      "While employed by petitioner, Ra\n"
     ]
    }
   ],
   "source": [
    "# IMPORT JSONS\n",
    "import os\n",
    "import glob\n",
    "from lxml import html\n",
    "\n",
    "start = time()\n",
    "jsons_as_series = []\n",
    "file_list = glob.glob('scotus_opinions/*.json')\n",
    "\n",
    "for filename in file_list:\n",
    "    with open(filename) as json_data:\n",
    "        json_1 = json.load(json_data)\n",
    "        jsons_as_series.append(pd.Series(json_1))\n",
    "\n",
    "opinions_df = pd.DataFrame(jsons_as_series)\n",
    "print(\"Elapsed opinion loading time:\", round((time()-start)/60, 1), 'minutes')\n",
    "\n",
    "\n",
    "# REMOVE DISMISSALS (coextensive with non-per-curiam, short texts with no majority opinion) \n",
    "# -- mostly denial of certiorari, but some misc. dismissals\n",
    "opinions_df['per_curiam'] = opinions_df.per_curiam.astype(bool)\n",
    "dismissals_index = opinions_df[\n",
    "    (~opinions_df.per_curiam)\n",
    "    & (opinions_df.html_with_citations.map(lambda x: len(x) < 5000))\n",
    "    & (opinions_df.html_with_citations.map(lambda x: x.lower().find('delivered the opinion of the court.') == -1))\n",
    "].index\n",
    "opinions_df = opinions_df.drop(dismissals_index)\n",
    "\n",
    "# LOAD AND LINK CLUSTERS\n",
    "# first, convert all http URLs to https (we'll need this for consistency of merging, and user convenience)\n",
    "def to_https(url):\n",
    "    if url[:5] != 'https':\n",
    "        url = 'https' + url[4:]\n",
    "    if url[:32] == 'https://www.courtlistener.com:80': # fix erroneous :80 urls\n",
    "        url = 'https://www.courtlistener.com' + url[32:]\n",
    "    return url\n",
    "\n",
    "opinions_df['cluster'] = opinions_df['cluster'].map(to_https)\n",
    "\n",
    "start = time()\n",
    "jsons_as_series = []\n",
    "file_list = glob.glob('scotus_clusters/*.json')\n",
    "\n",
    "for filename in file_list:\n",
    "    with open(filename) as json_data:\n",
    "        json_1 = json.load(json_data)\n",
    "        jsons_as_series.append(pd.Series(json_1))\n",
    "\n",
    "clusters_df = pd.DataFrame(jsons_as_series)\n",
    "clusters_df['resource_uri'] = clusters_df.resource_uri.map(to_https)\n",
    "print(\"Elapsed cluster loading time:\", round((time()-start)/60, 1), 'minutes')\n",
    "\n",
    "# merge info from clusters_df into opinions_df\n",
    "cases_df = pd.merge(opinions_df, \n",
    "                       clusters_df[['case_name',\n",
    "                                    'date_filed',\n",
    "                                    'federal_cite_one', \n",
    "                                    'resource_uri',\n",
    "                                    'scdb_id',\n",
    "                                    'scdb_decision_direction',\n",
    "                                    'scdb_votes_majority',\n",
    "                                    'scdb_votes_minority'\n",
    "                                   ]], \n",
    "                       how='left', \n",
    "                       left_on='cluster', \n",
    "                       right_on='resource_uri')\n",
    "\n",
    "del opinions_df, clusters_df\n",
    "print('1', cases_df.shape)\n",
    "\n",
    "# winnow down to the relevant columns (note: we'll drop the few cases of plain_text for consistency's sake)\n",
    "cases_df = cases_df[[\n",
    "    'case_name',\n",
    "    'author_str',\n",
    "    'date_filed',  \n",
    "    'federal_cite_one',\n",
    "    'per_curiam',\n",
    "    'author',  \n",
    "    'cluster',\n",
    "    'absolute_url',\n",
    "    'html_with_citations',\n",
    "    'scdb_id',\n",
    "    'scdb_decision_direction',\n",
    "    'scdb_votes_majority',\n",
    "    'scdb_votes_minority'\n",
    "]]\n",
    "\n",
    "# PARSE HTML\n",
    "start = time()\n",
    "cases_df['html_with_citations'] = cases_df.html_with_citations.astype(str)\n",
    "cases_df = cases_df[cases_df.html_with_citations.map(lambda x: len(x) > 1)] # eliminate one empty string\n",
    "cases_df['absolute_url'] = 'https://www.courtlistener.com' + cases_df.absolute_url\n",
    "def extract_text(raw_html):\n",
    "    return html.fromstring(raw_html).text_content().strip()\n",
    "cases_df['plain_text'] = cases_df.html_with_citations.map(lambda x: extract_text(x))\n",
    "is_empty_now = cases_df.plain_text.isnull()\n",
    "print('Total html parsing time:', round((time()-start)/60, 1), 'minutes')\n",
    "print(\"After parsing html, there are {} empty opinions remaining\".format(sum(is_empty_now)))\n",
    "cases_df = cases_df[~cases_df.per_curiam.isnull()]\n",
    "print('2', cases_df.shape)\n",
    "\n",
    "# remove remaining certiorari and misc. non-decisions: no listed decision direction, and no majority opinion\n",
    "non_decision_index = cases_df[(~cases_df.per_curiam) \n",
    "         & (cases_df.scdb_decision_direction.isnull())\n",
    "         & (cases_df.plain_text.map(\n",
    "             lambda x: x.lower().find('delivered the opinion of the court.')==-1))\n",
    "        ].index\n",
    "cases_df = cases_df.drop(non_decision_index)\n",
    "print('3', cases_df.shape)\n",
    "\n",
    "# remove duplicate cases\n",
    "# cases_df = cases_df.drop_duplicates(subset='federal_cite_one')\n",
    "\n",
    "# convert dates to datetime\n",
    "import datetime\n",
    "cases_df['date_filed'] = pd.to_datetime(cases_df.date_filed)\n",
    "cases_df['year_filed'] = cases_df.date_filed.map(lambda x: x.year)\n",
    "cases_df['year_filed'] = cases_df.year_filed.astype(int)\n",
    "# filter by date here if desired:\n",
    "# cases_df = cases_df[cases_df.year_filed >= 1970]\n",
    "\n",
    "# SANITY CHECK: do dates and titles match texts?\n",
    "checks = [83,1065,4508]\n",
    "for c in checks:\n",
    "    i = cases_df.index[c]\n",
    "    print(\n",
    "        '\\n\\n***SANITY CHECK {}***: \\n',\n",
    "        'CASE NAME:', cases_df.case_name[i], '\\n',\n",
    "        'CASE DATE:', cases_df.date_filed[i], '\\n', '\\n',\n",
    "        'CASE TEXT:\\n', cases_df.plain_text[i][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-07-09 00:00:00')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_df.date_filed.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing HTML into distinct opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed opinion parsing time: 26.6 minutes     \n"
     ]
    }
   ],
   "source": [
    "# PARSE plain text into separate opinions\n",
    "def find_author_listed_before(text, index):\n",
    "    '''\n",
    "    Returns first justice name preceding INDEX in the same sentence of TEXT.  If no justice named \n",
    "    between INDEX and the end of the previous sentence, returns None.\n",
    "    '''\n",
    "    text = text[:index].lower().replace('mr.','mr ')\n",
    "    start_index = text.rfind(\".\")\n",
    "    sentence = text[start_index:]\n",
    "    \n",
    "    justice_index = sentence.find(\"justice \")\n",
    "    if justice_index == -1:\n",
    "        justice_index = sentence.find(\"justice\\n\")\n",
    "        if justice_index == -1:\n",
    "            # catch rare format \"Smith, Justice, delivered the opinion of the court.\"\n",
    "            justice_index = sentence.find(\"justice, delivered\")\n",
    "            if justice_index != -1:\n",
    "                return \"justice \" + sentence[:justice_index].split()[-1][:-1] # name is prev word sans comma\n",
    "    if justice_index == -1:\n",
    "        return None\n",
    "\n",
    "    name_words = sentence[justice_index:].split()[:2]\n",
    "    name_words[-1] = name_words[-1].replace(',','') # remove trailing comma if present\n",
    "    name = \" \".join(name_words)\n",
    "    if name == 'justice dissentin': # catch rare false flag (actually a citation)\n",
    "        return None\n",
    "    return name\n",
    "\n",
    "def get_index_from_keyphrase(text, start_index, keyphrase, alternate_keyphrase=None):\n",
    "    '''\n",
    "    returns first index of KEYPHRASE(str) in TEXT[START_INDEX:] that has an author name \n",
    "    preceding it in the same sentence; returns None if none found\n",
    "    '''\n",
    "    search_text = text[start_index:]\n",
    "    index = search_text.find(keyphrase)\n",
    "    # if there isn't a justice preceding the keyphrase in the same sentence (rare),\n",
    "    # then this is a false flag.  Move on to the next occurrence of the keyphrase and repeat until true flag or end.\n",
    "    while index != -1 and find_author_listed_before(search_text, index + len(keyphrase)-2) is None:\n",
    "        new_index = search_text[(index + len(keyphrase)):].find(keyphrase)\n",
    "        index = new_index if new_index == -1 else new_index + (index + len(keyphrase))\n",
    "        # because the search started with the index of the prev find as 0\n",
    "    if index != -1:\n",
    "        index += len(keyphrase) + start_index\n",
    "    elif alternate_keyphrase is not None:\n",
    "        index = get_index_from_keyphrase(text, start_index, alternate_keyphrase, None)\n",
    "    return index\n",
    "\n",
    "def get_indices(text, per_curiam=False):\n",
    "    ''' \n",
    "    returns dictionary of beginning indices of majority / concurring / dissenting opinions in TEXT\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    indices = {}\n",
    "    bookmark = 0  # keeps track of where to start our next search\n",
    "    \n",
    "    if per_curiam:\n",
    "        indices['majority'] = text.find(\"per curiam.\")\n",
    "        if indices['majority'] != -1:\n",
    "            indices['majority'] += len(\"per curiam.\")\n",
    "    else:\n",
    "        indices['majority'] = get_index_from_keyphrase(text, 0, 'delivered the opinion of the court.', 'join.')\n",
    "\n",
    "    if indices['majority'] == -1: # short-circuit if there is no majority opinion: it's a dismissal (or an anomaly)\n",
    "        return indices\n",
    "    \n",
    "    bookmark = indices['majority']\n",
    "            \n",
    "    indices['first_concurring'] = get_index_from_keyphrase(\n",
    "        text,\n",
    "        bookmark,\n",
    "        'concurring.',\n",
    "        'concurring in the judgment.'\n",
    "    )\n",
    "    bookmark = max(bookmark, indices['first_concurring'])\n",
    "    \n",
    "    if indices['first_concurring'] == -1:\n",
    "        indices['second_concurring'] = -1\n",
    "    else:\n",
    "        indices['second_concurring'] = get_index_from_keyphrase(\n",
    "            text,\n",
    "            bookmark,\n",
    "            'concurring.'\n",
    "        )\n",
    "        bookmark = max(bookmark, indices['second_concurring'])\n",
    "    \n",
    "    indices['first_dissenting'] = get_index_from_keyphrase(\n",
    "        text,\n",
    "        bookmark,\n",
    "        'dissenting.'\n",
    "    )\n",
    "    bookmark = max(bookmark, indices['first_dissenting'])\n",
    "\n",
    "    \n",
    "    if indices['first_dissenting'] == -1:\n",
    "        indices['second_dissenting'] = -1\n",
    "    else:\n",
    "        indices['second_dissenting'] = get_index_from_keyphrase(\n",
    "            text,\n",
    "            bookmark,\n",
    "            'dissenting.'\n",
    "        )\n",
    "\n",
    "    return indices\n",
    "\n",
    "def remove_next_intro(text):\n",
    "    '''removes last sentence of text if it's introducing the next opinion '''\n",
    "    if text[-11:] in ['concurring.', 'dissenting.']:\n",
    "        end_of_prev_sentence = text[:-1].replace('Mr.','Mr ').rfind('.')\n",
    "        text = text[:end_of_prev_sentence + 2] # +2 to include last char and period\n",
    "    return text\n",
    "\n",
    "def split_and_label(text, per_curiam=False, include_concurring=True, include_second_dissent=True):\n",
    "    ''' returns a list of tuples formatted as (author, majority/concurring/dissenting, text)'''\n",
    "    opinions = []\n",
    "    indices = get_indices(text, per_curiam)\n",
    "    \n",
    "    if indices['majority'] == -1: # indicates empty / dismissal / haywire\n",
    "        return [None]\n",
    "    \n",
    "    majority_endpoint = indices['first_concurring'] if indices['first_concurring'] != -1 \\\n",
    "                            else indices['first_dissenting']\n",
    "    if per_curiam:\n",
    "        majority = (\n",
    "            'per_curiam',\n",
    "            'per_curiam',\n",
    "            remove_next_intro( text[indices['majority']:majority_endpoint] ).strip()\n",
    "        ) \n",
    "    else:\n",
    "        majority = (\n",
    "            find_author_listed_before(text, indices['majority']-1), # -1 to avoid including final period (find_author)\n",
    "            'majority',\n",
    "            remove_next_intro( text[indices['majority']:majority_endpoint] ).strip()\n",
    "        )\n",
    "    opinions.append(majority)\n",
    "    \n",
    "    concurring_endpoint = indices['second_concurring'] if indices['second_concurring'] != -1 \\\n",
    "                            else indices['first_dissenting']\n",
    "    if include_concurring and indices['first_concurring'] != -1:\n",
    "        first_concurring = (\n",
    "            find_author_listed_before(text, indices['first_concurring']-1),\n",
    "            'concurring',\n",
    "            remove_next_intro( text[indices['first_concurring']:concurring_endpoint] ).strip()\n",
    "        )\n",
    "        opinions.append(first_concurring)\n",
    "        \n",
    "    if indices['first_dissenting'] != -1:\n",
    "        first_dissenting = (\n",
    "            find_author_listed_before(text, indices['first_dissenting']-1),\n",
    "            'dissenting',\n",
    "            remove_next_intro( text[indices['first_dissenting']:indices['second_dissenting']] ).strip()\n",
    "        )\n",
    "        opinions.append(first_dissenting)\n",
    "        \n",
    "    if include_second_dissent and indices['second_dissenting'] != -1:\n",
    "        second_dissenting = (\n",
    "            find_author_listed_before(text, indices['second_dissenting']-1),\n",
    "            'second_dissenting',\n",
    "            remove_next_intro( text[indices['second_dissenting']:] ).strip()\n",
    "        )\n",
    "        opinions.append(second_dissenting)\n",
    "        \n",
    "    # clip \"notes\" section from end of the text of the last opinion in the case file\n",
    "    notes_index = opinions[-1][2].find('NOTES')\n",
    "    if notes_index == -1:\n",
    "        notes_index = opinions[-1][2].find('APPENDIXES')\n",
    "    if notes_index != -1:\n",
    "        opinions[-1] = (opinions[-1][0], \n",
    "                        opinions[-1][1], \n",
    "                        opinions[-1][2][:notes_index])\n",
    "        \n",
    "    return opinions\n",
    "\n",
    "columns = [\n",
    "    'author_name',\n",
    "    'category',\n",
    "    'per_curiam',\n",
    "    'case_name',\n",
    "    'date_filed',\n",
    "    'federal_cite_one',\n",
    "    'absolute_url',\n",
    "    'cluster',\n",
    "    'year_filed',\n",
    "    'scdb_id',\n",
    "    'scdb_decision_direction',\n",
    "    'scdb_votes_majority',\n",
    "    'scdb_votes_minority',\n",
    "    'text'\n",
    "]\n",
    "opinions_df = pd.DataFrame(columns=columns)\n",
    "counter = 0\n",
    "start = time()\n",
    "\n",
    "# .drop_duplicates(subset='federal_cite_one')\n",
    "for i in cases_df.index:\n",
    "    counter += 1\n",
    "    print(\"Processing row {} of {}\".format(counter, cases_df.shape[0]), end='\\r')\n",
    "    text = cases_df.plain_text[i]\n",
    "    per_curiam = cases_df.per_curiam[i]\n",
    "    opinions = split_and_label(text, per_curiam)\n",
    "    if opinions[0] is None: # if no majority opinion, either empty or something is haywire \n",
    "        continue\n",
    "    for opinion in opinions:\n",
    "        new_row = pd.Series(\n",
    "            [           \n",
    "                opinion[0], # author\n",
    "                opinion[1], # majority/concurring/dissenting\n",
    "                per_curiam,\n",
    "                cases_df.case_name[i],\n",
    "                cases_df.date_filed[i],\n",
    "                cases_df.federal_cite_one[i],\n",
    "                cases_df.absolute_url[i],\n",
    "                cases_df.cluster[i],\n",
    "                cases_df.year_filed[i],\n",
    "                cases_df.scdb_id[i],\n",
    "                cases_df.scdb_decision_direction[i],\n",
    "                cases_df.scdb_votes_majority[i],\n",
    "                cases_df.scdb_votes_minority[i],\n",
    "                opinion[2] # text\n",
    "            ],\n",
    "        index=columns)\n",
    "        \n",
    "#         print(new_row[:-1])\n",
    "        opinions_df.loc[opinions_df.shape[0]] = new_row # append without creating new object each time\n",
    "    \n",
    "print(\"Elapsed opinion parsing time:\", round((time()-start)/60, 1), 'minutes     ')\n",
    "\n",
    "# retyping as necessary\n",
    "opinions_df.per_curiam = opinions_df.per_curiam.astype(bool)\n",
    "opinions_df.year_filed = opinions_df.year_filed.astype(int)\n",
    "\n",
    "# drop any blank opinions that got read in (very few - about 7)\n",
    "opinions_df = opinions_df[opinions_df.text.map(lambda x: len(x) > 1)]\n",
    "\n",
    "# resolve apostrophe format discrepancies\n",
    "opinions_df.author_name = opinions_df.author_name.map(lambda x: x.replace('’','\\''))\n",
    "opinions_df.author_name = opinions_df.author_name.map(lambda x: x.replace('`','\\''))\n",
    "\n",
    "import string\n",
    "def format_name(name):\n",
    "    ''' strips punctuation and capitalizes first letter of each part of the name'''\n",
    "    if name == 'per_curiam':\n",
    "        return name\n",
    "    name = name.translate(str.maketrans('', '', string.punctuation.replace(\"'\",\"\")))\n",
    "    name = ' '.join([s[0].upper() + s[1:] for s in name.split()])\n",
    "    name = name\\\n",
    "        .replace('Homes','Holmes')\\\n",
    "        .replace('Mkinley','McKinley')\\\n",
    "        .replace('Mckinley','McKinley')\\\n",
    "        .replace('Duvall','Duval')\\\n",
    "        .replace('Duval','Duvall')\\\n",
    "        .replace('Brandies','Brandeis')\\\n",
    "        .replace('Branders','Brandeis')\\\n",
    "        .replace('Wilso','Wilson')\\\n",
    "        .replace('Bruger','Burger')\\\n",
    "        .replace('Authorginsburgauthor','Ginsburg')\\\n",
    "        .replace('Strongdelivered','Strong')\\\n",
    "        .replace('Conner',\"O'Connor\")\\\n",
    "        .replace(\"O'connor\",\"O'Connor\")\\\n",
    "        .replace('Millier','Miller')\\\n",
    "        .replace(\"M'kinley\",'McKinley')\\\n",
    "        .replace(\"Mcreynolds\",'McReynolds')\n",
    "    \n",
    "    return name\n",
    "\n",
    "opinions_df['author_name'] = opinions_df.author_name.apply(format_name)\n",
    "\n",
    "# remove very rare (mostly erroneous) author_name values if desired:\n",
    "# rare_authors = list(opinions_df.author_name.value_counts()[opinions_df.author_name.value_counts() <= 5].index)\n",
    "# opinions_df = opinions_df[~opinions_df.author_name.isin(rare_authors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (35781, 14)\n",
      "earliest date: 1797-02-13\n",
      "latest date: 2020-07-09\n"
     ]
    }
   ],
   "source": [
    "print('shape:', opinions_df.shape)\n",
    "print('earliest date:', opinions_df.date_filed.min())\n",
    "print('latest date:', opinions_df.date_filed.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinions_df.to_csv('all_opinions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinions_df[opinions_df.year_filed.astype(str) >= '1970'].to_csv('opinions_since_1970.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35781, 14)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author_name                    0\n",
       "category                       0\n",
       "per_curiam                     0\n",
       "case_name                      0\n",
       "date_filed                     0\n",
       "federal_cite_one           16586\n",
       "absolute_url                   0\n",
       "cluster                        0\n",
       "year_filed                     0\n",
       "scdb_id                     1763\n",
       "scdb_decision_direction     1768\n",
       "scdb_votes_majority         1763\n",
       "scdb_votes_minority         1763\n",
       "text                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinions_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_name</th>\n",
       "      <th>category</th>\n",
       "      <th>per_curiam</th>\n",
       "      <th>case_name</th>\n",
       "      <th>date_filed</th>\n",
       "      <th>federal_cite_one</th>\n",
       "      <th>absolute_url</th>\n",
       "      <th>cluster</th>\n",
       "      <th>year_filed</th>\n",
       "      <th>scdb_id</th>\n",
       "      <th>scdb_decision_direction</th>\n",
       "      <th>scdb_votes_majority</th>\n",
       "      <th>scdb_votes_minority</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Justice Roberts</td>\n",
       "      <td>majority</td>\n",
       "      <td>False</td>\n",
       "      <td>McCutcheon v. Federal Election Comm'n</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.courtlistener.com/opinion/2659301/...</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v3/clus...</td>\n",
       "      <td>2014</td>\n",
       "      <td>2013-033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>There is no right more basic in our democracy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Justice Thomas</td>\n",
       "      <td>concurring</td>\n",
       "      <td>False</td>\n",
       "      <td>McCutcheon v. Federal Election Comm'n</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.courtlistener.com/opinion/2659301/...</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v3/clus...</td>\n",
       "      <td>2014</td>\n",
       "      <td>2013-033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I adhere to the view that this Court’s decisio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Justice Breyer</td>\n",
       "      <td>dissenting</td>\n",
       "      <td>False</td>\n",
       "      <td>McCutcheon v. Federal Election Comm'n</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.courtlistener.com/opinion/2659301/...</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v3/clus...</td>\n",
       "      <td>2014</td>\n",
       "      <td>2013-033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Nearly 40 years ago in Buckley v. Valeo, 424 U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_name    category  per_curiam  \\\n",
       "0  Justice Roberts    majority       False   \n",
       "1   Justice Thomas  concurring       False   \n",
       "2   Justice Breyer  dissenting       False   \n",
       "\n",
       "                               case_name  date_filed federal_cite_one  \\\n",
       "0  McCutcheon v. Federal Election Comm'n  2014-04-02              NaN   \n",
       "1  McCutcheon v. Federal Election Comm'n  2014-04-02              NaN   \n",
       "2  McCutcheon v. Federal Election Comm'n  2014-04-02              NaN   \n",
       "\n",
       "                                        absolute_url  \\\n",
       "0  https://www.courtlistener.com/opinion/2659301/...   \n",
       "1  https://www.courtlistener.com/opinion/2659301/...   \n",
       "2  https://www.courtlistener.com/opinion/2659301/...   \n",
       "\n",
       "                                             cluster  year_filed   scdb_id  \\\n",
       "0  https://www.courtlistener.com/api/rest/v3/clus...        2014  2013-033   \n",
       "1  https://www.courtlistener.com/api/rest/v3/clus...        2014  2013-033   \n",
       "2  https://www.courtlistener.com/api/rest/v3/clus...        2014  2013-033   \n",
       "\n",
       "   scdb_decision_direction  scdb_votes_majority  scdb_votes_minority  \\\n",
       "0                      1.0                  5.0                  4.0   \n",
       "1                      1.0                  5.0                  4.0   \n",
       "2                      1.0                  5.0                  4.0   \n",
       "\n",
       "                                                text  \n",
       "0  There is no right more basic in our democracy ...  \n",
       "1  I adhere to the view that this Court’s decisio...  \n",
       "2  Nearly 40 years ago in Buckley v. Valeo, 424 U...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinions_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10022\n",
      "8685\n"
     ]
    }
   ],
   "source": [
    "print(round(opinions_df[opinions_df.category=='dissenting'].text.map(lambda x: len(x)).median()))\n",
    "print(round(opinions_df[opinions_df.category=='second_dissenting'].text.map(lambda x: len(x)).median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Justice Gorsuch       47\n",
       "Justice Baldwin       42\n",
       "Justice Woodbury      42\n",
       "Justice Washington    29\n",
       "Justice Kavanaugh     20\n",
       "Justice McKinley      17\n",
       "Justice Barbour       15\n",
       "Justice Byrnes        15\n",
       "Justice Trimble       13\n",
       "Justice Livingston     9\n",
       "Justice Duvall         7\n",
       "Justice Todd           5\n",
       "Justice Chase          5\n",
       "Justice Stated         3\n",
       "Justice Johnston       2\n",
       "Justice O2122          2\n",
       "Justice Chie           2\n",
       "Justice 458            1\n",
       "Justice Harean         1\n",
       "Justice Parsons        1\n",
       "Justice Iiunt          1\n",
       "Justice Thomson        1\n",
       "Justice Cushing        1\n",
       "Justice Daniels        1\n",
       "Justice Pearson        1\n",
       "Justice Wilson         1\n",
       "Justice Or             1\n",
       "Justice With           1\n",
       "Justice Breese         1\n",
       "Justice Now            1\n",
       "Justice Concurring     1\n",
       "Justice Connor         1\n",
       "Justice Paterson       1\n",
       "Justice Mokenna        1\n",
       "Justice And            1\n",
       "Name: author_name, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinions_df.author_name.value_counts()[opinions_df.author_name.value_counts() < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.courtlistener.com/opinion/108553/united-states-v-midwest-video-corp/\n"
     ]
    }
   ],
   "source": [
    "print(cases_df.iloc[855].absolute_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_concurring': -1,\n",
       " 'first_dissenting': -1,\n",
       " 'majority': 875,\n",
       " 'second_concurring': -1,\n",
       " 'second_dissenting': -1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_indices(cases_df.loc[5467, 'plain_text'].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate federal_cite_one duplicates\n",
    "spoiler: they're by and large not actual duplicate rows (a rare few are).  Usually they're two events pertaining to the same (but sometimes differently titled) case, e.g., a motion to proceed a certain way passes, or it's postponed because the plaintiff didn't show, and then there's a separate event for a real hearing of the case.  Or something like that.  At any rate, different texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feds = cases_df[\n",
    "    (~cases_df.federal_cite_one.isnull())\n",
    "    & ~(cases_df.federal_cite_one == '')\n",
    "    & (cases_df.federal_cite_one.duplicated())\n",
    "].federal_cite_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 24731\n",
      "Hamburg-American Line Terminal & Navigation Co. v. United States (Two Cases). Atlas Line S. S. Co. v. Same\n",
      "1928-05-14 00:00:00\n",
      "ID: \n",
      "Author: \n",
      "\n",
      " 30153\n",
      "Hamburg-American Co. v. United States\n",
      "2005-03-04 00:00:00\n",
      "ID: \n",
      "Author: \n",
      "\n",
      " 24731\n",
      "Text:\n",
      " 277 U.S. 138\n",
      "    48 S. Ct. 470\n",
      "    72 L. Ed. 822\n",
      "    HAMBURG-AMERICAN LINE TERMINAL & NAVIGATION CO.v.UNITED STATES (two cases).  ATLAS LINE S. S. CO.  v.  SAME.\n",
      "    Nos. 3-5.\n",
      "    Argued and Submitted April 25, 1928.\n",
      "    Decided May 14, 1928.\n",
      "    \n",
      "      Under Trading with the Enemy Act, § 2(a), 50 USCA Appendix, § 2(a), Comp. St. § 3115 1/2 aa, property of domestic corporations, seized during war with Germany cannot be treated as owned by enemy, so as to preclude recovery of compensation from United States for use thereof, because their entire capital stock belonged to German corporation.\n",
      "      Congress, having power to direct forfeiture of all property beneficially owned by enemy subjects during war, could provide for seizure thereof, followed by such compensation as President might determine, as was done by Trading with the Enemy Act (50 USCA Appendix; Comp. St. § 3115 1/2 a et seq.).\n",
      "      In action for value of tug boats, launch, etc., taken by United States from enemy owned domestic corporations under Trading with the Enemy Act (50 USCA Appendix; Comp. St. § 3115 1/2 a et seq.), petition alleging that property was taken and used disclosed adequate ground for recovery to that e\n",
      "\n",
      " 30153\n",
      "Text:\n",
      " 277 U.S. 138 (1928)\n",
      "HAMBURG-AMERICAN LINE TERMINAL & NAVIGATION COMPANY\n",
      "v.\n",
      "UNITED STATES.\n",
      "SAME\n",
      "v.\n",
      "SAME.\n",
      "ATLAS LINE STEAMSHIP COMPANY\n",
      "v.\n",
      "SAME.\n",
      "Nos. 3, 4, 5.\n",
      "Supreme Court of United States.\n",
      "Argued April 25, 1928.\n",
      "Decided May 14, 1928.\n",
      "APPEALS FROM THE COURT OF CLAIMS.\n",
      "*139 Mr. Charles H. Le Fevre for appellants.\n",
      "Solicitor General Mitchell for the United States.\n",
      "MR. JUSTICE McREYNOLDS delivered the opinion of the Court.\n",
      "These appeals were taken June 16, 1924, from judgments of the Court of Claims which sustained demurrers to the petitions. For the views of that Court see Deutsch-Australische Dampfschiffs-Gesellschaft, Appellant, v. The *140 United States, 59 Ct. Cls. 461. Appellants are incorporated under the laws of New Jersey and their entire capital stock has long been owned by the Hamburg-American Line, a German corporation.\n",
      "In Cause No. 3 the appellant seeks to recover (1) compensation for the use of certain docks and piers, New York harbor, seized by the United States April 6, 1917, and used by them until June 28, 1918; and (2) interest on the sum awarded by the President (December 3, 1918) as compensation for the same property, from June 28, 1918, when title was taken thereto u\n"
     ]
    }
   ],
   "source": [
    "i = -5\n",
    "df = cases_df[cases_df.federal_cite_one == feds.iloc[i]]\n",
    "for j, row in df.iterrows():\n",
    "    print('\\n', j)\n",
    "    print(row.case_name)\n",
    "    print(row.date_filed)\n",
    "    print('ID:', row.scdb_id)\n",
    "    print('Author:', row.author_str)\n",
    "    \n",
    "for j, row in df.iterrows():\n",
    "    print('\\n', j)\n",
    "    print('Text:\\n', row.plain_text[:1200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check clusters-opinions match rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30407, 24)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64163, 51)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-07-24'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_df.date_filed[~cases_df.date_filed.isnull()].astype(str).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resource_uri', 'id', 'absolute_url', 'date_created', 'date_modified']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in opinions_df.columns if col in clusters_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " id\n",
      "opinion nulls 0\n",
      "cluster nulls 0\n",
      "opinion dupes 0\n",
      "cluster dupes 0\n",
      "\n",
      " resource_uri\n",
      "opinion nulls 0\n",
      "cluster nulls 0\n",
      "opinion dupes 0\n",
      "cluster dupes 0\n"
     ]
    }
   ],
   "source": [
    "for col in ['id','resource_uri']:\n",
    "    print('\\n', col)\n",
    "    print('opinion nulls', opinions_df[col].isnull().sum())\n",
    "    print('cluster nulls', clusters_df[col].isnull().sum())\n",
    "    print('opinion dupes', opinions_df[col].duplicated().sum())\n",
    "    print('cluster dupes', clusters_df[col].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29922, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.merge(\n",
    "    left = clusters_df[['id', 'date_filed']],\n",
    "    right = opinions_df[['id','author']],\n",
    "    left_on='id',\n",
    "    right_on='id',\n",
    "    how='inner'\n",
    ")\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30406, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.merge(\n",
    "    left = clusters_df[['resource_uri', 'date_filed']],\n",
    "    right = opinions_df[['cluster','author']],\n",
    "    left_on='resource_uri',\n",
    "    right_on='cluster',\n",
    "    how='inner'\n",
    ")\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# incorporate uWash dataset if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8966, 53)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uw_df = pd.read_csv('scdb_uwash_data.csv', engine='python')\n",
    "uw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['caseId', 'docketId', 'caseIssuesId', 'voteId', 'dateDecision',\n",
       "       'decisionType', 'usCite', 'sctCite', 'ledCite', 'lexisCite', 'term',\n",
       "       'naturalCourt', 'chief', 'docket', 'caseName', 'dateArgument',\n",
       "       'dateRearg', 'petitioner', 'petitionerState', 'respondent',\n",
       "       'respondentState', 'jurisdiction', 'adminAction', 'adminActionState',\n",
       "       'threeJudgeFdc', 'caseOrigin', 'caseOriginState', 'caseSource',\n",
       "       'caseSourceState', 'lcDisagreement', 'certReason', 'lcDisposition',\n",
       "       'lcDispositionDirection', 'declarationUncon', 'caseDisposition',\n",
       "       'caseDispositionUnusual', 'partyWinning', 'precedentAlteration',\n",
       "       'voteUnclear', 'issue', 'issueArea', 'decisionDirection',\n",
       "       'decisionDirectionDissent', 'authorityDecision1', 'authorityDecision2',\n",
       "       'lawType', 'lawSupp', 'lawMinor', 'majOpinWriter', 'majOpinAssigner',\n",
       "       'splitVote', 'majVotes', 'minVotes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uw_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1/10/1947'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uw_df.dateArgument[~uw_df.dateArgument.isnull()].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     2029\n",
       "8.0     1743\n",
       "2.0     1450\n",
       "9.0     1232\n",
       "3.0      680\n",
       "10.0     406\n",
       "7.0      361\n",
       "4.0      348\n",
       "12.0     312\n",
       "5.0      116\n",
       "6.0      102\n",
       "11.0      99\n",
       "13.0      24\n",
       "14.0       4\n",
       "Name: issueArea, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uw_df.issueArea.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8730, 7)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.merge(\n",
    "    left=cases_df[['scdb_id','federal_cite_one','case_name','date_filed']],\n",
    "    right=uw_df[['caseId','usCite','sctCite']],\n",
    "    left_on='scdb_id',\n",
    "    right_on='caseId',\n",
    "    how='inner'\n",
    ")\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15297, 7)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.merge(\n",
    "    left=opinions_df[['scdb_id','federal_cite_one','case_name','date_filed']],\n",
    "    right=uw_df[['caseId','usCite','sctCite']],\n",
    "    left_on='scdb_id',\n",
    "    right_on='caseId',\n",
    "    how='inner'\n",
    ")\n",
    "test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
